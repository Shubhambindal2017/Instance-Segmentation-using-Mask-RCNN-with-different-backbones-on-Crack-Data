{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2_REST_API_using_flask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS-lusUoWOQb"
      },
      "source": [
        "##Simple REST-API for model created in task-1, I have kept it simple by using the implementation code to get the architecture and then load the weights, I might saved it into a frozen graph format and then do the inference on it##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD7iY9PpYuid"
      },
      "source": [
        "####Clone Assignement Repository####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDRceEb8BIIb",
        "outputId": "2ba2fdff-ed29-42d7-f1ca-b7e20a3ffc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "## Need to do from this ...\n",
        "from getpass import getpass\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "user = getpass('Github user')\n",
        "password = getpass('Github password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + urllib.parse.quote_plus(password)\n",
        "#... to this, as the repository is private\n",
        "\n",
        "!git clone  https://$GITHUB_AUTH@github.com/loong/shubham-fv-test-mask-rcnn.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Github user··········\n",
            "Github password··········\n",
            "Cloning into 'shubham-fv-test-mask-rcnn'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 56 (delta 12), reused 48 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwsS87C0WcwI"
      },
      "source": [
        "####Clone Matterport's MASK-RCNN Implementation####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM5CZbSOWbqF",
        "outputId": "51649a44-406e-4e4b-f20f-a003dbdca3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 111.85 MiB | 11.65 MiB/s, done.\n",
            "Resolving deltas: 100% (563/563), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WFKz311WrhR"
      },
      "source": [
        "####To use flask on colab, install flask-ngrok####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPC4sTzQCcf5",
        "outputId": "fde0bc24-e9a8-444e-f197-9126120a606b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_fV4bWfFyPJ"
      },
      "source": [
        "####Get Trained Weights### "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK4xiJN7GiBz",
        "outputId": "516a6451-4bbb-4b62-e8d5-b4094603acde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!mkdir ./weights\n",
        "%cd ./weights\n",
        "\n",
        "!gdown --id 1-NJLyi6T3uNM-wjJTn3XOyUrZkEztcvw"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/weights\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-NJLyi6T3uNM-wjJTn3XOyUrZkEztcvw\n",
            "To: /content/weights/mask_rcnn_crack_0025.h5\n",
            "256MB [00:01, 148MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrkBN-DGBFPf"
      },
      "source": [
        "#####Switching to Tensorflow 1.x#####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRyBCUIVBEVh",
        "outputId": "49af4f9a-f90c-4745-8a79-8f6e17c78573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZH2YCz6aNPs",
        "outputId": "07412636-4462-4f70-9ce1-c0ca1d53cd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/Mask_RCNN\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from matplotlib import patches,  lines\n",
        "from matplotlib.patches import Polygon\n",
        "import skimage\n",
        "from skimage.measure import find_contours\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA_NYHIDVhyB",
        "outputId": "0a15f8fc-6c0b-4e8c-8c56-5a449d3249f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "class InferenceConfig(Config):\n",
        "\n",
        "  NAME = \"crack\"\n",
        "\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "  # Number of classes (including background)\n",
        "  NUM_CLASSES = 1 + 1  # background + 1 crack (class)\n",
        "\n",
        "  # Our training image size is (448, 448)\n",
        "  IMAGE_MIN_DIM = 256\n",
        "  IMAGE_MAX_DIM = 256\n",
        "\n",
        "  DETECTION_MIN_CONFIDENCE = 0.8\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir = '/content/weights')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA531411p6qQ"
      },
      "source": [
        "def load_image(image_path):\n",
        "    \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = skimage.io.imread(image_path)\n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if image.ndim != 3:\n",
        "        image = skimage.color.gray2rgb(image)\n",
        "    # If has an alpha channel, remove it for consistency\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[..., :3]\n",
        "    return image\n",
        "\n",
        "def get_masked_predicted_img(image, width_orig, height_orig, boxes, masks, class_ids, class_names, scores, \n",
        "                             save_img_path, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=True,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = visualize.random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    \n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "    \n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            #import pdb; pdb.set_trace()\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "        ax.text(x1, y1 + 8, caption,\n",
        "                color='w', size=11, backgroundcolor=\"none\")\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        \n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        \n",
        "        \n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "\n",
        "    #import pdb; pdb.set_trace()\n",
        "\n",
        "    ax.imshow(masked_image.astype(np.uint8))\n",
        "    \n",
        "    plt.savefig(save_img_path, bbox_inches='tight', pad_inches=-0.5,orientation= 'landscape')\n",
        "    plt.close()\n",
        "\n",
        "    Image.open(save_img_path).resize((width_orig, height_orig)).save(save_img_path)\n",
        "    #if auto_show:\n",
        "    #    plt.show()\n",
        "\n",
        "def masked_percentage_func(masks):\n",
        "\n",
        "  masks_num = masks.shape[-1]\n",
        "\n",
        "  if masks_num != 0:\n",
        "    bool_sum_across_diff_masks = masks[:,:,0].copy()\n",
        "\n",
        "  if masks_num > 1:\n",
        "    for mask_num in range(1, masks_num):\n",
        "\n",
        "      bool_sum_across_diff_masks = bool_sum_across_diff_masks + masks[:,:,mask_num]\n",
        "\n",
        "  pixels_masks = bool_sum_across_diff_masks.sum()\n",
        "\n",
        "  return pixels_masks/(masks.shape[0]*masks.shape[1])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJiS3BlOAnvU"
      },
      "source": [
        "####Set Session before loading the weights####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxFStoNgAtlb",
        "outputId": "76ae28e1-2002-4dbe-9e55-b57794339f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.python.keras.backend import set_session\n",
        "\n",
        "session = tensorflow.Session()\n",
        "graph = tensorflow.get_default_graph()\n",
        "set_session(session)\n",
        "\n",
        "# Load trained weights\n",
        "model_path = '/content/weights/mask_rcnn_crack_0025.h5'\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from  /content/weights/mask_rcnn_crack_0025.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSJIT5tylMym"
      },
      "source": [
        "##Click on the *ngrok.io link##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBJ9FhiXCWm3",
        "outputId": "7176a437-dbce-443a-9b9f-c244beb43068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "%cd /content/shubham-fv-test-mask-rcnn/task_2\n",
        "\n",
        "import os\n",
        "import time\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, render_template\n",
        "\n",
        "\n",
        "\n",
        "UPLOAD_FOLDER = './static'\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_file():\n",
        "    if request.method == 'POST':\n",
        "        if 'file1' not in request.files:\n",
        "            return 'there is no file in form!'\n",
        "        file1 = request.files['file1']\n",
        "        path = os.path.join(app.config['UPLOAD_FOLDER'], file1.filename)\n",
        "\n",
        "        file1.save(path)\n",
        "\n",
        "        #Loading and pre-processing the image\n",
        "        orig_image = load_image(path)\n",
        "\n",
        "        #print(image.shape)\n",
        "        image, window, scale, padding, crop = utils.resize_image(orig_image,\n",
        "                                                  min_dim=inference_config.IMAGE_MIN_DIM,\n",
        "                                                  min_scale=inference_config.IMAGE_MIN_SCALE,\n",
        "                                                  max_dim=inference_config.IMAGE_MAX_DIM,\n",
        "                                                  mode=inference_config.IMAGE_RESIZE_MODE)\n",
        "\n",
        "        #print(image.shape)\n",
        "        save_img_path = path[:-4] + '_predicted.jpg'\n",
        "\n",
        "        with session.as_default():\n",
        "            with session.graph.as_default():\n",
        "              # inference on model\n",
        "              results = model.detect([image], verbose=0)\n",
        "              r = results[0]\n",
        "\n",
        "        get_masked_predicted_img(image, orig_image.shape[0], orig_image.shape[1], r['rois'], r['masks'], r['class_ids'], \n",
        "                            ['BG', 'crack'] , r['scores'], save_img_path = save_img_path)\n",
        "\n",
        "        time.sleep(10) # as the process is asynchronous, increase this if found no output image is shown\n",
        "\n",
        "        masked_percentage = masked_percentage_func(r['masks'])\n",
        "        \n",
        "        return render_template('result.html', results=[file1.filename, os.path.basename(save_img_path), {\"percent_masked\": masked_percentage*100}])\n",
        "    return render_template('home.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/shubham-fv-test-mask-rcnn/task_2\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://62678689f13b.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [28/Sep/2020 11:42:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Sep/2020 11:42:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [28/Sep/2020 11:43:23] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Sep/2020 11:43:24] \"\u001b[37mGET /static/0.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Sep/2020 11:43:24] \"\u001b[37mGET /static/0_predicted.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZW22_CKMTFr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}